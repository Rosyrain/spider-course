### 入门实例-某京新发地（Post请求）

### 一、前言 

​	在前文，我们有提到，随时时代的发展，网络越来越发达，网站被访问的次数在极具增长，而我们传统的前后端不分离的写法，早已无法满足业务需求。所以现在更多的网站选择前后端分离，即前端只进行页面的样式设计和数据展示，而关于各种数据和各种资源的处理由后端进行。前端想拿到数据，就需要对对应的API接口发送请求，拿到数据。

​	所以文本将以Post请求的方式，讲解前后端分离的页面，该如何去获取我们想要的数据。

​	目标`url:  http://www.xinfadi.com.cn/priceDetail.html`,去获取这个月的大白菜价格波动

![image-20240528194921714](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405281949793.png)



### 二、具体操作

> 牢记我们爬虫的业务流程：
>
> 1.分析数据所在位置
>
> 2.获取数据
>
> 3.数据处理



**①：数据位置分析**

打开F12(如果没有资源显示，请刷新页面)，进行检查元素，确定位置

![image-20240528195016980](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405281950029.png)



**②数据获取**

在这，大家可以仿照上一篇文章去尝试一下，看看是否可以拿到我们想要的数据，下面给出示例代码

```python
import requests

url = 'http://www.xinfadi.com.cn/priceDetail.html'

_headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0'
}

resp = requests.get(url,headers=_headers)
content = resp.content
print(content)
```

![image-20240528195428610](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405281954699.png)

从上图我们可以发现，我们得到的结果中，并没有我们想要的数据

**解释：**

我们先找到数据的位置，然后发送请求，拿到响应，查看是否存在，但是会发现，在

```
url = "http://www.xinfadi.com.cn/priceDetail.html"
```

返回的响应体里面，我们是找不到大白菜的菜价的，那说明菜价的内容是动态加载的，他不存在于我们的页面源代码里面。而我们用request.get()大部分都是请求的页面源代码（页面源代码的查看--在页面处，点击**右键**，有一个选项是  **查看页面源代码**，或者在网址前面加上 view-source:   比如`view-source:http://www.xinfadi.com.cn/priceDetail.html`）

![image-20240528194022027](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405281940136.png)

在这个地方，大家可以思考一下，一般什么资源会动态加载，什么资源会写到页面源代码里面。大家可以找自己感兴趣的网站进行尝试。



**③：重新分析数据位置**

​	根据前文，我们可以知道大白菜本月内的价格波动，它是动态加载出来的，这个时候就需要我们进行抓包。我们打开F12，点击 Network/网络 ，然后`ctrl`+`F`或者点击搜索，输入大白菜或者它的一个价格。

![image-20240528195921987](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405281959049.png)

根据上图，你可以发现原来数据都存储在这个文件当中，那么这个文件从何而来呢？

**打开标头，让我们看看一些关键信息**

![image-20240528200032869](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282000891.png)

打开标头，我们可以看见一个请求的url，还有一个请求方法。这个url就是我们需要更新的新请求的url，而这个请求方法，确定了我们是`requests.get()`还是`requests.post()`。

那大家可以思考一下，上篇文章中和本文上面的代码，为什么要用get请求呢？

![image-20240528200415055](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282004133.png)

那我们得到的响应内容是什么？其实就在响应里面。

![image-20240528200450051](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282004081.png)



**④：数据获取**

​	回到本文，我们发现数据发送的url `http://www.xinfadi.com.cn/getPriceData.html`，同时也知道了发送请求，那么就可以尝试直接Post发送请求，看看是否可以拿到数据。

请注意Post请求需要提交表单，就像你登录，发文章一样，需要提交东西。而提交的东西在  **负载** 中可以查看。

![image-20240528202320489](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282023581.png)

这点可以用re正则快速进行内容格式修改，方便我们写入python的字典当中 

`ctrl`+`R`   打开内容替换，其中$1为参数1，$2为参数2，上面的(.*?)为re正则表达式的内容，后续会讲解。

![image-20240528202407535](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282024586.png)

代码：

```python
url = 'http://www.xinfadi.com.cn/getPriceData.html'

_headers = {
    'Accept': '*/*',
    'Accept-Encoding': 'gzip, deflate',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
    'Content-Length': '140',
    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
    'Host': 'www.xinfadi.com.cn',
    'Origin': 'http://www.xinfadi.com.cn',
    'Proxy-Connection': 'keep-alive',
    'Referer': 'http://www.xinfadi.com.cn/priceDetail.html',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0',
    'X-Requested-With': 'XMLHttpRequest',
}

#注意表单的两种传递方式，一种是在 负载 当中点击 查看源，将他的内容复制下来，一种就是下面存入字典种然后利用urllib库进行解析。

# data = 'limit=20&current=1&pubDateStartTime=2024%2F05%2F01&pubDateEndTime=2024%2F05%2F28&prodPcatid=&prodCatid=&prodName=%E5%A4%A7%E7%99%BD%E8%8F%9C'
data = {
    'limit':'20',
    'current':'1',
    'pubDateStartTime':'2024/05/01',
    'pubDateEndTime':'2024/05/28',
    'prodPcatid':'',
    'prodCatid':'',
    'prodName':'大白菜',
}

resp = requests.post(url,headers=_headers,data=urllib.parse.urlencode(data))
content = resp.content
# print(content)
```

我们可以发现，我们确实获得了数据，但是仍有一点差别，这是因为数据的形式是json格式，这需要我们使用python自带的库进行处理一下。（ 有关json大家可以参考这一篇[什么是 JSON？JSON详解](https://juejin.cn/post/7263369673126182969?searchId=20240528200933C3286B73622C910052F7)  ）

```python
data = json.loads(content)
print(data)
```

![image-20240528201135047](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282011155.png)

可以发现，我们已经获取了我们想要的数据了。



## 三、数据处理

数据获取部分：

```python
import urllib

import requests
import json
from pyecharts.charts import Line
from pyecharts.options import TitleOpts, ToolboxOpts, LegendOpts, InitOpts, DataZoomOpts
import pandas as pd

url = 'http://www.xinfadi.com.cn/getPriceData.html'

_headers = {
    'Accept': '*/*',
    'Accept-Encoding': 'gzip, deflate',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
    'Content-Length': '140',
    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
    'Host': 'www.xinfadi.com.cn',
    'Origin': 'http://www.xinfadi.com.cn',
    'Proxy-Connection': 'keep-alive',
    'Referer': 'http://www.xinfadi.com.cn/priceDetail.html',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0',
    'X-Requested-With': 'XMLHttpRequest',
}

# data = 'limit=20&current=1&pubDateStartTime=2024%2F05%2F01&pubDateEndTime=2024%2F05%2F28&prodPcatid=&prodCatid=&prodName=%E5%A4%A7%E7%99%BD%E8%8F%9C'
data = {
    'limit':'20',
    'current':'1',
    'pubDateStartTime':'2024/05/01',
    'pubDateEndTime':'2024/05/28',
    'prodPcatid':'',
    'prodCatid':'',
    'prodName':'大白菜',
}

resp = requests.post(url,headers=_headers,data=urllib.parse.urlencode(data))
content = resp.content
# print(content)

data = json.loads(content)
# print(data)

# 提取所需信息
prod_name = data['list'][0]['prodName']
low_prices = [float(item['lowPrice']) for item in data['list']]
high_prices = [float(item['highPrice']) for item in data['list']]
avg_prices = [float(item['avgPrice']) for item in data['list']]
places = [item['place'] for item in data['list']]
pub_dates = [item['pubDate'].split(' ')[0] for item in data['list']]
```

存入excel表部分：

```python
# 创建 DataFrame
df = pd.DataFrame({
    '蔬菜名称': [prod_name] * len(low_prices),
    '最低价格': low_prices,
    '最高价格': high_prices,
    '平均价格': avg_prices,
    '产地': places,
    '日期': pub_dates
})

# 写入 Excel 文件
df.to_excel('vegetable_price_data.xlsx', index=False)
print('数据已成功写入 vegetable_price_data.xlsx 文件中。')
```

![image-20240528204510252](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282045287.png)

生成图片部分：

```python
# 设置标题、工具栏、图例和滑动选择框
line.set_global_opts(
    title_opts=TitleOpts(title=f'{prod_name}价格波动图'),
    toolbox_opts=ToolboxOpts(pos_left='auto',pos_right='auto',pos_bottom="auto",pos_top="20px"),
    legend_opts=LegendOpts(),
    datazoom_opts=[
        DataZoomOpts(
            is_show=True,
            type_='slider',
            xaxis_index=[0],
            range_start=0,
            range_end=100
        )
    ]
)

# 渲染图表
line.render('vegetable_price_chart.html')
print('价格波动图已成功生成为 vegetable_price_chart.html 文件。')
```

![image-20240528204342166](https://rosyrain.oss-cn-hangzhou.aliyuncs.com/img2/202405282043235.png)



### 四、结语

​	在我们去分析数据所在的位置的时候，优先考虑它是否存在于页面源代码当中，如果不存在，那么就借助抓包工具进行位置分析。同时不要请求头的完整以及参数的添加。根据上文，大家可以尝试去使用一个变量去接受蔬菜名或者其他，进行**其他菜价的获取 **或者 **翻页 **(自动获取第2页,第3页的数据....)处理。



​	有任何问题欢迎大家的评论和指正。再次声明，本专栏只做技术探讨，严谨商用，恶意攻击等。

这是我的 GitHub 主页：[Rosyrain (github.com)](https://github.com/Rosyrain)  `https://github.com/rosyrain`，里面有一些我学习时候的笔记或者代码。本专栏的文档和源码存到spider-course的仓库下。

欢迎大家**Follow/Star/Fork**三连。
